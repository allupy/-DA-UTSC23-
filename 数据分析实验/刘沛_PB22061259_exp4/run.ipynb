{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with missing values:\n",
      "node-caps      8\n",
      "breast-quad    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#1.Q1\n",
    "import pandas as pd  \n",
    "  \n",
    "# 读取csv文件  \n",
    "df = pd.read_csv('C:\\\\Users\\\\86180\\\\Desktop\\\\数据分析实验四\\\\data2.csv')  \n",
    "\n",
    "# 检查哪些特征含有缺失值  \n",
    "missing_values = df.isnull().sum()  \n",
    "print(\"Features with missing values:\")  \n",
    "print(missing_values[missing_values > 0])  # 只显示含有缺失值的特征  \n",
    "  \n",
    "# 删除所有含空缺值的行  \n",
    "df = df.dropna()  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for tumor-size:\n",
      "tumor-size\n",
      "30-34     57\n",
      "25-29     51\n",
      "20-24     48\n",
      "15-19     29\n",
      "14-Oct    28\n",
      "40-44     22\n",
      "35-39     19\n",
      "0-4        8\n",
      "50-54      8\n",
      "9-May      4\n",
      "45-49      3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for inv-nodes:\n",
      "inv-nodes\n",
      "0-2       209\n",
      "5-Mar      34\n",
      "8-Jun      17\n",
      "11-Sep      7\n",
      "15-17       6\n",
      "14-Dec      3\n",
      "24-26       1\n",
      "Name: count, dtype: int64\n",
      "Value counts for tumor-size:\n",
      "tumor-size\n",
      "30-34    57\n",
      "25-29    51\n",
      "20-24    48\n",
      "15-19    29\n",
      "10-14    28\n",
      "40-44    22\n",
      "35-39    19\n",
      "0-4       8\n",
      "50-54     8\n",
      "5-9       4\n",
      "45-49     3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for inv-nodes:\n",
      "inv-nodes\n",
      "0-2      209\n",
      "3-5       34\n",
      "6-8       17\n",
      "9-11       7\n",
      "15-17      6\n",
      "12-14      3\n",
      "24-26      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1.Q2.（10%）当前数据表未能正确处理部分数据值的文本与日期表示类型\n",
    "# 检查tumor-size列的值分布  \n",
    "print(\"Value counts for tumor-size:\")  \n",
    "print(df['tumor-size'].value_counts())  \n",
    "  \n",
    "# 检查inv-nodes列的值分布  \n",
    "print(\"\\nValue counts for inv-nodes:\")  \n",
    "print(df['inv-nodes'].value_counts())  \n",
    "\n",
    "# 修正tumor-size列中的异常值 \n",
    "replacements = {\n",
    "    '14-Oct':'10-14',\n",
    "    '9-May':'5-9',\n",
    "    '5-Mar':'3-5',\n",
    "    '8-Jun':'6-8',\n",
    "    '11-Sep':'9-11',\n",
    "    '14-Dec':'12-14'\n",
    "}\n",
    "# 使用replace方法替换值  \n",
    "df['inv-nodes'].replace(replacements, inplace=True)  \n",
    "df['tumor-size'].replace(replacements, inplace=True) \n",
    "\n",
    "# 检查tumor-size列的值分布  \n",
    "print(\"Value counts for tumor-size:\")  \n",
    "print(df['tumor-size'].value_counts())  \n",
    "  \n",
    "# 检查inv-nodes列的值分布  \n",
    "print(\"\\nValue counts for inv-nodes:\")  \n",
    "print(df['inv-nodes'].value_counts())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Class=no-recurrence-events': 0, 'Class=recurrence-events': 1, 'age=10-19': 2, 'age=20-29': 3, 'age=30-39': 4, 'age=40-49': 5, 'age=50-59': 6, 'age=60-69': 7, 'age=70-79': 8, 'age=80-89': 9, 'age=90-99': 10, 'menopause=lt40': 11, 'menopause=ge40': 12, 'menopause=premeno': 13, 'tumor-size=0-4': 14, 'tumor-size=5-9': 15, 'tumor-size=10-14': 16, 'tumor-size=15-19': 17, 'tumor-size=20-24': 18, 'tumor-size=25-29': 19, 'tumor-size=30-34': 20, 'tumor-size=35-39': 21, 'tumor-size=40-44': 22, 'tumor-size=45-49': 23, 'tumor-size=50-54': 24, 'tumor-size=55-59': 25, 'inv-nodes=0-2': 26, 'inv-nodes=3-5': 27, 'inv-nodes=6-8': 28, 'inv-nodes=9-11': 29, 'inv-nodes=12-14': 30, 'inv-nodes=15-17': 31, 'inv-nodes=18-20': 32, 'inv-nodes=21-23': 33, 'inv-nodes=24-26': 34, 'inv-nodes=27-29': 35, 'inv-nodes=30-32': 36, 'inv-nodes=33-35': 37, 'inv-nodes=36-39': 38, 'node-caps=yes': 39, 'node-caps=no': 40, 'deg-malig=1': 41, 'deg-malig=2': 42, 'deg-malig=3': 43, 'breast=left': 44, 'breast=right': 45, 'breast-quad=left_up': 46, 'breast-quad=left_low': 47, 'breast-quad=right_up': 48, 'breast-quad=right_low': 49, 'breast-quad=central': 50, 'irradiat=yes': 51, 'irradiat=no': 52}\n"
     ]
    }
   ],
   "source": [
    "#1.Q3\n",
    "# 读取包含特征映射的Excel文件  \n",
    "mapping_df = pd.read_excel('C:\\\\Users\\\\86180\\\\Desktop\\\\数据分析实验四\\\\variables.xlsx') \n",
    "# 初始化索引与属性值的对应关系字典  \n",
    "ind2val = {} \n",
    "\n",
    "# 遍历映射DataFrame，为每个特征创建映射关系  \n",
    "flag = 0\n",
    "for index, row in mapping_df.iterrows():  \n",
    "    feature_name = row['Variable Name']  #这一列包含了特征名  \n",
    "    value_to_index_pairs = row['Description'].split(',')  # 映射之间用逗号分隔    \n",
    "  \n",
    " # 遍历每个值到索引的配对  \n",
    "    for pair in value_to_index_pairs:  \n",
    "        pair= pair.strip()  \n",
    "        # 创建特征名和具体值的组合作为字典的键  \n",
    "        key = f'{feature_name}={pair}'  \n",
    "          \n",
    "        # 添加映射到ind2val字典  \n",
    "        ind2val[key] = flag \n",
    "        flag = flag+1\n",
    "  \n",
    "print(ind2val) \n",
    "\n",
    "# 遍历数据集的每一列  \n",
    "for column in df.columns:  \n",
    "    # 检查该列是否在映射字典的特征名中  \n",
    "    for key, value in ind2val.items():  \n",
    "        feature_name, feature_value = key.split('=')  \n",
    "        if column == feature_name:  \n",
    "            # 替换该列中的值为字典中对应的索引  \n",
    "            df[column] = df[column].replace(feature_value, value)  \n",
    "#print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Itemsets   Support\n",
      "0               (0)  0.707581\n",
      "1               (1)  0.501805\n",
      "2               (2)  0.465704\n",
      "3              (12)  0.447653\n",
      "4              (13)  0.541516\n",
      "5              (26)  0.754513\n",
      "6              (40)  0.797834\n",
      "7              (44)  0.527076\n",
      "8              (45)  0.480144\n",
      "9              (52)  0.776173\n",
      "10         (40, 44)  0.418773\n",
      "11         (40, 13)  0.425993\n",
      "12         (26, 13)  0.404332\n",
      "13         (26, 52)  0.649819\n",
      "14          (0, 52)  0.592058\n",
      "15         (44, 52)  0.415162\n",
      "16         (40, 26)  0.722022\n",
      "17         (26, 44)  0.404332\n",
      "18          (0, 26)  0.599278\n",
      "19         (52, 13)  0.404332\n",
      "20          (0, 40)  0.617329\n",
      "21         (40, 52)  0.675090\n",
      "22      (0, 26, 52)  0.530686\n",
      "23      (0, 40, 52)  0.545126\n",
      "24     (40, 26, 52)  0.635379\n",
      "25      (40, 0, 26)  0.577617\n",
      "26  (0, 26, 40, 52)  0.523466\n"
     ]
    }
   ],
   "source": [
    " \n",
    "import numpy as np  \n",
    "   \n",
    "# 将DataFrame转换为列表的列表形式，每个内部列表代表一个事务  \n",
    "def convert_df_to_transactions(df):  \n",
    "    transactions = df.values.tolist()    \n",
    "    return transactions  \n",
    "  \n",
    "# 计算项集的支持度  \n",
    "def calculate_support(transactions, itemset):  \n",
    "    count = sum(set(itemset).issubset(transaction) for transaction in transactions)  \n",
    "    return count / len(transactions)  \n",
    "  \n",
    "def generate_candidate_one_set(Lk_minus_1, all_items):  \n",
    "    candidates = set()  \n",
    "      \n",
    "    # 遍历Lk_minus_1中的每个项  \n",
    "    for item in Lk_minus_1:  \n",
    "        # 生成新的候选项，通过添加不在Lk_minus_1中但在all_items中的项  \n",
    "        remaining_items = all_items - Lk_minus_1  \n",
    "        for new_item in remaining_items:  \n",
    "            # 创建一个新的候选项，通过在(k-1)项集中添加new_item  \n",
    "            candidate = Lk_minus_1 | frozenset([new_item])  \n",
    "            candidates.add(candidate)  \n",
    "      \n",
    "    return candidates\n",
    "# Apriori算法实现  \n",
    "def apriori(transactions, min_support=0.4):  \n",
    "    if not isinstance(transactions, list):  \n",
    "        transactions = convert_df_to_transactions(transactions)  # 确保transactions是列表的列表  \n",
    "    #print(transactions)\n",
    "    \n",
    "    all_items = set(item for transaction in transactions for item in transaction)  \n",
    " \n",
    "    # 1. 初始化频繁1项集  \n",
    "    C1 = [frozenset([item]) for item in all_items]  \n",
    "    F1 = [itemset for itemset in C1 if calculate_support(transactions, itemset) >= min_support]  \n",
    "    k = 2  \n",
    "    frequent_itemsets = F1[:]  \n",
    "    #print(frequent_itemsets[-1])  \n",
    "    # 2. 迭代生成并测试候选项集  \n",
    "    while True:  \n",
    "        Ck = set()  # 初始化候选项集集合  \n",
    "  \n",
    "        # 遍历频繁(k-1)项集列表  \n",
    "        for Lk_minus_1 in frequent_itemsets:  \n",
    "            if len(Lk_minus_1) == k-1:  # 确保只处理长度为k-1的项集  \n",
    "                # 为每个频繁(k-1)项集生成候选项集  \n",
    "                #print(Lk_minus_1)\n",
    "                candidate_sets = generate_candidate_one_set(Lk_minus_1, all_items)  \n",
    "                Ck.update(candidate_sets)  # 将生成的候选项集添加到Ck中  \n",
    "         \n",
    "        # 计算候选项集的支持度  \n",
    "        Ck_counts = {itemset: calculate_support(transactions, itemset) for itemset in Ck}  \n",
    "          \n",
    "        # 保留支持度大于或等于min_support的项集  \n",
    "        Fk = [itemset for itemset, count in Ck_counts.items() if count >= min_support]  \n",
    "          \n",
    "        # 如果没有新的频繁项集，则停止  \n",
    "        if len(Fk) == 0:  \n",
    "            break  \n",
    "          \n",
    "        # 更新频繁项集列表  \n",
    "        frequent_itemsets.extend(Fk)  \n",
    "        k += 1  \n",
    "      \n",
    "    # 转换为DataFrame格式（如果需要的话）  \n",
    "    frequent_itemsets_with_support = [(itemset, calculate_support(transactions, itemset)) for itemset in frequent_itemsets]  \n",
    "    frequent_itemsets_df = pd.DataFrame(frequent_itemsets_with_support, columns=['Itemsets', 'Support'])  \n",
    "      \n",
    "    return frequent_itemsets_df\n",
    "  \n",
    "# 示例用法  \n",
    "transactions = convert_df_to_transactions(df)   \n",
    "frequent_itemsets = apriori(transactions, min_support=0.4)  \n",
    "print(frequent_itemsets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({52}, 0, 0.7627906976744185, 1.0780256288561936)\n",
      "({26}, 0, 0.7942583732057417, 1.1224978029489308)\n",
      "({40}, 0, 0.7737556561085973, 1.0935220241942933)\n",
      "({26, 52}, 0, 0.8166666666666667, 1.1541666666666668)\n",
      "({40, 52}, 0, 0.8074866310160427, 1.1411928407726726)\n",
      "({40, 26}, 0, 0.7999999999999999, 1.1306122448979592)\n",
      "({40, 26, 52}, 0, 0.8238636363636364, 1.1643378942486085)\n"
     ]
    }
   ],
   "source": [
    "#2.Q2.（20%）基于提取出的频繁项集，以最小置信度阈值为0.75，提取形如X->{0}的强关联规则，并分别输出它们的置信度和提升度。\n",
    "#print(frequent_itemsets['Itemsets'])\n",
    "\n",
    "def calculate_support(item_or_set, df):  \n",
    "    # 查找单个项或项集的支持度  \n",
    "    return df[df['Itemsets'].apply(lambda x: item_or_set.issubset(x))]['Support'].iloc[0] if not df.empty else 0  \n",
    "  \n",
    "def calculate_confidence(antecedent, consequent, df):      \n",
    "    # 查找X ∪ {item}的支持度  \n",
    "    union_support = calculate_support(antecedent | {consequent}, df)  \n",
    "    # 查找X的支持度  \n",
    "    antecedent_support = calculate_support(antecedent, df)  \n",
    "    # 计算置信度  \n",
    "    return union_support / antecedent_support if antecedent_support > 0 else 0  \n",
    "  \n",
    "def calculate_lift(antecedent, consequent, df):  \n",
    "    # 查找X的支持度  \n",
    "    antecedent_support = calculate_support(antecedent, df)  \n",
    "    # 查找{item}的支持度  \n",
    "    consequent_support = calculate_support({consequent}, df)  \n",
    "    # 查找X ∪ {item}的支持度  \n",
    "    union_support = calculate_support(antecedent | {consequent}, df)  \n",
    "    # 计算提升度  \n",
    "    return union_support / (antecedent_support * consequent_support) if (antecedent_support > 0 and consequent_support > 0) else 0  \n",
    "  \n",
    "  \n",
    "def generate_strong_rules(df, min_confidence=0.75):  \n",
    "    strong_rules = []  \n",
    "    for index, row in df.iterrows():  \n",
    "        itemset = row['Itemsets']  \n",
    "        #support = row['Support']  \n",
    "        # 只考虑长度大于1的项集  \n",
    "        if len(itemset) > 1:  \n",
    "             for item in itemset:\n",
    "                if item == 0:\n",
    "                # 生成形如 X->{0} 的规则，其中 X = itemset - {0}  ,\n",
    "                    antecedent = set(tuple(sorted(itemset - {item})))                 \n",
    "                # 计算置信度  \n",
    "                    confidence = calculate_confidence(antecedent, item, df)  \n",
    "                    lift = calculate_lift(antecedent, item, df)\n",
    "                # 如果置信度大于或等于最小置信度，则添加规则  \n",
    "                    if confidence >= min_confidence:  \n",
    "                        rule = (antecedent, item, confidence,lift)  \n",
    "                        strong_rules.append(rule)  \n",
    "    return strong_rules \n",
    "the_rules = generate_strong_rules(frequent_itemsets, min_confidence=0.75)\n",
    "for rule in the_rules:\n",
    "    print(rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'irradiat=no'}, 'Class=no-recurrence-events', 0.7627906976744185, 1.0780256288561936)\n",
      "({'inv-nodes=0-2'}, 'Class=no-recurrence-events', 0.7942583732057417, 1.1224978029489308)\n",
      "({'node-caps=no'}, 'Class=no-recurrence-events', 0.7737556561085973, 1.0935220241942933)\n",
      "({'irradiat=no', 'inv-nodes=0-2'}, 'Class=no-recurrence-events', 0.8166666666666667, 1.1541666666666668)\n",
      "({'irradiat=no', 'node-caps=no'}, 'Class=no-recurrence-events', 0.8074866310160427, 1.1411928407726726)\n",
      "({'inv-nodes=0-2', 'node-caps=no'}, 'Class=no-recurrence-events', 0.7999999999999999, 1.1306122448979592)\n",
      "({'irradiat=no', 'inv-nodes=0-2', 'node-caps=no'}, 'Class=no-recurrence-events', 0.8238636363636364, 1.1643378942486085)\n"
     ]
    }
   ],
   "source": [
    "#2.Q3.（10%）参考ind2val中索引与属性值的对应关系，对以上频繁项集和关联规则结果进行简要分析和总结。\n",
    "\n",
    "#字典ind2val中含有数字索引和病人特征的键值对，现在打算将这些强关联规则返回为原来的特征关联，方便分析\n",
    "\n",
    "# 创建逆映射字典  \n",
    "inverse_dict = {v: k for k, v in ind2val.items()}  \n",
    "\n",
    "replaced_list = []  \n",
    "for rule in the_rules:  \n",
    "    # 替换集合\n",
    "    antecedent = set()  # 假设集合中只有一个元素 \n",
    "    for element in rule[0]:\n",
    "        antecedent.add(inverse_dict.get(element,element))          \n",
    "    # 替换整数  \n",
    "    item = inverse_dict.get(rule[1], rule[1])  # 使用get方法来避免KeyError，如果整数没有替换值则保持不变  \n",
    "    # 构建新的元组并添加到新列表中  \n",
    "    replaced_list.append((antecedent, item, rule[2], rule[3]))  \n",
    "\n",
    "for x in replaced_list:\n",
    "    print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
